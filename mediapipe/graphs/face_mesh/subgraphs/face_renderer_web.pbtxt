# MediaPipe face mesh rendering subgraph.

type: "FaceRendererWeb"

# GPU image. (GpuBuffer)
input_stream: "IMAGE:input_image"
# Collection of detected/predicted faces, each represented as a list of
# landmarks. (std::vector<NormalizedLandmarkList>)
input_stream: "LANDMARKS:multi_face_landmarks"
# Regions of interest calculated based on palm detections.
# (std::vector<NormalizedRect>)
input_stream: "NORM_RECTS:rects"
# Detected palms. (std::vector<Detection>)
input_stream: "DETECTIONS:detections"

# GPU image with rendered data. (GpuBuffer)
output_stream: "IMAGE:output_video"

node {
  calculator: "ImagePropertiesCalculator"
  input_stream: "IMAGE_GPU:input_image"
  output_stream: "SIZE:image_size"
}

# Outputs each element of multi_face_landmarks at a fake timestamp for the rest
# of the graph to process. At the end of the loop, outputs the BATCH_END
# timestamp for downstream calculators to inform them that all elements in the
# vector have been processed.
node {
  calculator: "BeginLoopNormalizedLandmarkListVectorCalculator"
  input_stream: "ITERABLE:multi_face_landmarks"
  output_stream: "ITEM:face_landmarks"
  output_stream: "BATCH_END:end_timestamp"
}

# Collects a RenderData object for each hand into a vector. Upon receiving the
# BATCH_END timestamp, outputs the vector of RenderData at the BATCH_END
# timestamp.
node {
  calculator: "EndLoopRenderDataCalculator"
  input_stream: "ITEM:face_landmarks"
  input_stream: "BATCH_END:end_timestamp"
  output_stream: "ITERABLE:multi_face_landmarks_render_data"
}

# Draws annotations and overlays them on top of the input images.
node {
  calculator: "RenderGPUBufferToCanvasCalculator"
  input_stream: "VIDEO_IN:image_size"
  output_stream: "VIDEO_OUT:output_video"
}


